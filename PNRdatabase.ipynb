{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script Code\n",
    "## Import relevant packages/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Second_counter(time):\n",
    "    return int(time[0]) * 36000 + int(time[1]) * 3600 + int(time[2]) * 600 + int(time[3]) * 60 + int(time[4]) * 10 + int(time[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get data from Place log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPlace(placeFile):\n",
    "   \n",
    "    with open(placeFile,\"r\") as pf:\n",
    "        lines = pf.readlines()\n",
    "    for line in lines:\n",
    "        RD = re.search(\"Row Direction\", line)\n",
    "        CU = re.search(\"Core Utilization\", line)\n",
    "        NR = re.search(\"Number Of Rows\", line)\n",
    "        CW = re.search(\"Core Width\", line)\n",
    "        CH = re.search(\"Core Height\", line)\n",
    "        AR = re.search(\"Aspect Ratio =\", line)\n",
    "        DB = re.search(\"Double Back\", line)\n",
    "        FFR = re.search(\"Flip First Row\", line)\n",
    "        SFFR = re.search(\"Start From First Row\", line)\n",
    "        ST = re.search(r\"Starting ICC placement run at: \\S+ \\d+ \\d+ (\\d+):(\\d+):(\\d+)\",line)\n",
    "        ET = re.search(r\"ICC placement run @: \\S+ \\d+ \\d+ (\\d+):(\\d+):(\\d+)\",line)\n",
    "        \n",
    "        if RD:\n",
    "            RowDirection = re.match(r\"\\sRow Direction = (\\w+)\", line).group(1)\n",
    "        if CU:\n",
    "            CoreUtils = re.match(r\"\\sCore Utilization = (\\S+)\", line).group(1)\n",
    "        if NR:\n",
    "            NoRows = re.match(r\"\\sNumber Of Rows = (\\S+)\", line).group(1)\n",
    "        if CW:\n",
    "            CoreWidth = re.match(r\"\\sCore Width = (\\S+)\", line).group(1)\n",
    "        if CH:\n",
    "            CoreHeight = re.match(r\"\\sCore Height = (\\S+)\", line).group(1)\n",
    "        if AR:\n",
    "            AspectRatio = re.match(r\"\\sAspect Ratio = (\\S+)\", line).group(1)\n",
    "        if DB:\n",
    "            DoubleBack = re.match(r\"\\sDouble Back (\\w+)\", line).group(1)\n",
    "        if FFR:\n",
    "            FlipFirstRow = re.match(r\"\\sFlip First Row = (\\w+)\", line).group(1)\n",
    "        if SFFR:\n",
    "            StartFromFirstRow = re.match(r\"\\sStart From First Row = (\\w+)\", line).group(1)\n",
    "        if ST:\n",
    "            StartTime = ST.group(1)+ST.group(2)+ST.group(3)\n",
    "        if ET:\n",
    "            EndTime = ET.group(1)+ET.group(2)+ET.group(3)            \n",
    "    \n",
    "    RunTimePlace = Second_counter(EndTime)-Second_counter(StartTime)    \n",
    "    \n",
    "    return RowDirection,float(CoreUtils),int(NoRows),float(CoreWidth),float(CoreHeight),float(AspectRatio),DoubleBack,FlipFirstRow,StartFromFirstRow,RunTimePlace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get data from Route log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRoute(routeFile):\n",
    "    with open(routeFile,\"r\") as rf:\n",
    "        lines = rf.readlines()\n",
    "    Violations=0\n",
    "    RoutedContacts=0\n",
    "    TotalNets=0\n",
    "    flagAV=0\n",
    "    LayerMX = dict(M1=0,M2=0,M3=0,M4=0,M5=0,M6=0,M7=0)\n",
    "    LayerLX = dict(L1=0,L2=0,L3=0,L4=0)\n",
    "    LayerBX = dict(BA=0,BB=0,BD=0,BE=0,BG=0)\n",
    "    LayerFX = dict(FA=0,FB=0)\n",
    "    Layer3X = dict(U3T=0,U3A=0)\n",
    "    LayerLB = dict(LB=0)\n",
    "    for line in lines:\n",
    "        V = re.search(\"VIOLATIONS\", line)\n",
    "        RC = re.search(\"Routed Contacts\", line)\n",
    "        LMX = re.search('Layer\\s+(M[1-7])\\s+:\\s+(\\d+)',line)\n",
    "        LLX = re.search('Layer\\s+(L[1-7])\\s+:\\s+(\\d+)',line)\n",
    "        LBX = re.search('Layer\\s+(B[1-7|A-Z])\\s+:\\s+(\\d+)',line)\n",
    "        LFX = re.search('Layer\\s+(F[A-Z])\\s+:\\s+(\\d+)',line)\n",
    "        L3X = re.search('Layer\\s+(3[A-Z])\\s+:\\s+(\\d+)',line)\n",
    "        LLB = re.search('Layer\\s+(LB)\\s+:\\s+(\\d+)',line)\n",
    "        TN = re.search(\"Total number of nets\", line)\n",
    "        AV = re.search(\"Total number of antenna violations = (\\d+)\", line)\n",
    "        ST = re.search(r\"route and Metalfill\\) at: \\S+ \\d+ \\d+ (\\d+):(\\d+):(\\d+)\",line)   \n",
    "        ET = re.search(r\"finished zroute_final run @: \\S+ \\d+ \\d+ (\\d+):(\\d+):(\\d+)\",line)\n",
    "        \n",
    "        if V:\n",
    "            Violations = re.match(r\"\\s@@@@@@@ TOTAL VIOLATIONS =\t(\\S+)\", line).group(1)\n",
    "        if RC:\n",
    "            RoutedContacts = re.match(r\"Total Number of Routed Contacts =       (\\S+)\", line).group(1)\n",
    "        if TN:\n",
    "            TotalNets = re.match(r\"Total number of nets = (\\d+)\", line).group(1)\n",
    "        if LMX:\n",
    "            LayerMX[LMX.group(1)] = int(LMX.group(2))\n",
    "        if LLX:\n",
    "            LayerLX[LLX.group(1)] = int(LLX.group(2))\n",
    "        if LBX:\n",
    "            LayerBX[LBX.group(1)] = int(LBX.group(2))\n",
    "        if LFX:\n",
    "            LayerFX[LFX.group(1)] = int(LFX.group(2))\n",
    "        if L3X:\n",
    "            Layer3X[L3X.group(1)] = int(L3X.group(2))\n",
    "        if LLB:\n",
    "            LayerLB[LLB.group(1)] = int(LLB.group(2))\n",
    "        if AV:\n",
    "            flagAV=1\n",
    "            AntennaViolations = re.match(r\"Total number of antenna violations = (\\d+)\", line).group(1)\n",
    "        if ST:\n",
    "            StartTime = ST.group(1)+ST.group(2)+ST.group(3)\n",
    "        if ET:\n",
    "            EndTime = ET.group(1)+ET.group(2)+ET.group(3)\n",
    "            \n",
    "    if flagAV==0:\n",
    "        AntennaViolations = 0\n",
    "        \n",
    "    RunTimeRoute = Second_counter(EndTime)-Second_counter(StartTime)\n",
    "    \n",
    "    return int(Violations),int(RoutedContacts),int(TotalNets),LayerMX,LayerLX,LayerBX,LayerFX,Layer3X,LayerLB,int(AntennaViolations),RunTimeRoute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append data from both functions to a list\n",
    " - if other file of same metal stack, date and 40LP is found, add data to same row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictResultsList = []\n",
    "stackCounter = 0\n",
    "\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\Asus\\Desktop\\My Documents\\NUS\\IA\\40LP test\\40LP\", topdown=False):\n",
    "    for name in files:\n",
    "        filename = (os.path.join(root, name))\n",
    "        flagOtherFile = 0\n",
    "        if 'place' in name:\n",
    "            type40LP = str(filename).split('\\\\')[9]\n",
    "            metalStack = str(filename).split('\\\\')[10]\n",
    "            date = str(filename).split('\\\\')[11][10:16]  \n",
    "            for length in range(len(dictResultsList)):\n",
    "                if metalStack == dictResultsList[length][0] and date == dictResultsList[length][1] and type40LP == dictResultsList[length][2]:\n",
    "                    k = length\n",
    "                    flagOtherFile = 1\n",
    "            if flagOtherFile == 0:\n",
    "                dictResultsList.append([])\n",
    "                k = stackCounter\n",
    "                dictResultsList[k].append(metalStack)\n",
    "                dictResultsList[k].append(date)\n",
    "                dictResultsList[k].append(type40LP)\n",
    "                stackCounter = stackCounter + 1\n",
    "            \n",
    "            dictResultsList[k].append(dataPlace(filename))\n",
    "                \n",
    "        if 'route' in name:\n",
    "            metalStack = str(filename).split('\\\\')[10]\n",
    "            date = str(filename).split('\\\\')[11][13:19]\n",
    "            type40LP = str(filename).split('\\\\')[9]\n",
    "            for length in range(len(dictResultsList)):\n",
    "                if metalStack == dictResultsList[length][0] and date == dictResultsList[length][1] and type40LP == dictResultsList[length][2]:\n",
    "                    k = length\n",
    "                    flagOtherFile = 1\n",
    "            if flagOtherFile == 0:\n",
    "                dictResultsList.append([])\n",
    "                k = stackCounter\n",
    "                dictResultsList[k].append(metalStack)\n",
    "                dictResultsList[k].append(date)\n",
    "                dictResultsList[k].append(type40LP)\n",
    "                stackCounter = stackCounter + 1\n",
    "                \n",
    "            dictResultsList[k].append(dataRoute(filename))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results to csv file (PNRdatabase3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('PNRdatabase3.csv', mode='a') as csv_file:\n",
    "    fieldnames = ['Violations','AntennaViolations','RunTimeRoute','RunTimePlace','LayerM1','LayerM2','LayerM3','LayerM4','LayerM5','LayerM6','LayerM7','LayerL1','LayerL2','LayerL3','LayerL4','LayerBA','LayerBB','LayerBD','LayerBE','LayerBG','LayerFA','LayerFB','LayerU3T','LayerU3A','LayerLB', 'ViaCounts', 'NetCount','MetalStack','Date','Type40LP', 'RowDirection', 'RowCount', 'CoreUtil', 'CoreWidth', 'CoreHeight', 'AspectRatio', 'DoubleBack', 'FlipFirstRow', 'StartfromFirstRow']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    if os.stat('PNRdatabase3.csv').st_size == 0:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for i in range(len(dictResultsList)):\n",
    "        dictResults = dict(Violations=dictResultsList[i][4][0],AntennaViolations=dictResultsList[i][4][9],RunTimeRoute=dictResultsList[i][4][10],RunTimePlace=dictResultsList[i][3][9],LayerM1=dictResultsList[i][4][3].get('M1'),LayerM2=dictResultsList[i][4][3].get('M2'),LayerM3=dictResultsList[i][4][3].get('M3'),LayerM4=dictResultsList[i][4][3].get('M4'),LayerM5=dictResultsList[i][4][3].get('M5'),LayerM6=dictResultsList[i][4][3].get('M6'),LayerM7=dictResultsList[i][4][3].get('M7'),LayerL1=dictResultsList[i][4][4].get('L1'),LayerL2=dictResultsList[i][4][4].get('L2'),LayerL3=dictResultsList[i][4][4].get('L3'),LayerL4=dictResultsList[i][4][4].get('L4'),LayerBA=dictResultsList[i][4][5].get('BA'),LayerBB=dictResultsList[i][4][5].get('BB'),LayerBD=dictResultsList[i][4][5].get('BD'),LayerBE=dictResultsList[i][4][5].get('BE'),LayerBG=dictResultsList[i][4][5].get('BG'),LayerFA=dictResultsList[i][4][6].get('FA'),LayerFB=dictResultsList[i][4][6].get('FB'),LayerU3T=dictResultsList[i][4][7].get('U3T'),LayerU3A=dictResultsList[i][4][7].get('U3A'),LayerLB=dictResultsList[i][4][8].get('LB'), ViaCounts=dictResultsList[i][4][1],NetCount= dictResultsList[i][4][2], MetalStack= dictResultsList[i][0],Date=dictResultsList[i][1],Type40LP=dictResultsList[i][2],RowDirection= dictResultsList[i][3][0], RowCount= dictResultsList[i][3][2],CoreUtil= dictResultsList[i][3][1],CoreWidth= dictResultsList[i][3][3], CoreHeight= dictResultsList[i][3][4], AspectRatio= dictResultsList[i][3][5], DoubleBack= dictResultsList[i][3][6], FlipFirstRow= dictResultsList[i][3][7], StartfromFirstRow= dictResultsList[i][3][8])\n",
    "        writer.writerow(dictResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "seen = set() # set for fast O(1) amortized lookup\n",
    "for line in fileinput.FileInput('PNRdatabase3.csv', inplace=1):\n",
    "    if line in seen:\n",
    "        continue # skip duplicate\n",
    "    seen.add(line)\n",
    "    print(line), # standard output is now redirected to the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
